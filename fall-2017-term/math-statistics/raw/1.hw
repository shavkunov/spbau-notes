# Лекция 1

## Организационное

Будут ДЗ и контрольные работы. Примерно надо сделать 80\%. Точные правила будут озвучены ближе к концу семестра.

## Книги.
Чернова Матем. статистика 
Ивченко, Медведев "..."
Матстат это теорвер, только наоборот(статистика решает обратные задачи)

## Теорвер:
$(\Omega, \mathbb{F}, P)$
$x_1, x_2 \dots$ - с.в. с известным распределением 
$s_n = x_1 + \dots + x_n$

УЗБЧ: $@S_n/n@ \under{п.н} -> EX_1$
это типичное утверждение в теорвере

## Матстат:
Зафиксируем исход: $\omega_0$
$x(w_0)$ — реализация с.в.
Цель — извлечь информацию о распределении.

Есть некоторое вероятностное пространство: $(\Omega, \mathbb{F}, P)$, про которое мы больше вспоминать не будем.
Статистический эксперимент — следующий набор объектов: $(\mathfrak{X}$, $\mathbb{A}$, $\{ P_{\theta}$, $\theta \in \Theta \})$
$\Theta \subset \R^d$, $\mathbb{A}$ -- $\sigma$-алгебра из $\mathfrak{X}$, $P_{\theta}$, $\theta$ -- меры
$X_1, X_2, ...$ — независимые одинаково распределенные случайные величины(iid): $\Omega -> \mathfrak{X}$
$X_i ~ P_{\theta}$ (но мы не знаем какие именно $\theta$)
$x_1, x_2, \dots, x_n$ -- наблюдения(одна шт) ??
$x_1, \dots, x_n$ -- выборка(объема n)

В теор. статистике выборка -- набор случайных величин
В практической это $x_1(\omega_0), \dots, x_n(\omega_0)$ -- набор чисел, реализация случайных величин.

## Задачи статистики

### 1. Оценивание параметров
    a) Точечное оценивание
    $X_i$ -- с.в.
Хотим найти хорошую с.в. $T(X_1, \dots, X_n) \approx \theta$
Критерий состоятельности: $\forall \theta T_n \under{при $n -> \infty$ по $P_{\theta}$} -> \theta$ 
Например, последовательность оценок: $T_n = T_n(X_1,...X_n)$ где $X_1, ... X_n$ -- выборка разного объема
Пример: $\theta = EX$ $\overline{X} = \overline{X} \under{ЗБЧ} -> \theta$ ?
                                                  

Другой критерий: $\A E_{\theta}T = \theta$(мат.ожидание в предположении $P_{\theta}$ -- распределения). Это называется несмещенностью.

Как сравнивать оценки? Мы будем в основном с помощью среднего квадратичного отклонения.

\4 = \theta

$T_1$ эффективнее $T_2$, если $E_{\4}(T_1 - \4)^2 <= E_{\4}(T_2 - \4)^2$
    б) Задача интервального оценивания.
В пункте а) мы предлагали число, здесь будет интервал. (будет некоторая неаккуратность, когда будем обсуждать подробно там будет ок). Аналогия погрешностей

\7 = \gamma

$(T_1, T_2)$ — доверительный интервал уровня $\7$
если $P_\4 (T_1 < \4 < T_2) = \7$
### 2. Проверка статистических гипотез

\5 = \Theta
\8 = \cup

В самом простом виде: 
$\5 = \5_0 \8 \5_1$ их пересечение = пустое множество
$H_0 : \4 \in \5_0$ — основная(нулевая) гипотеза
$H_1 : \4 \in \5_1$ — альтернатива

\1 = \mathfrak{X}

Задача построить такую функцию и в некотором смысле оптимально. $n$ — объем выборки
$\phi: \1^n -> {0, 1}$ $\phi$ выбирает гипотезу
В чем проблема:

\9 = \alpha

\begin{tabular}{c|c|c|c}
                & реальность       &                &               \\ \hline 
наше решение    &                  &    $H_0$       &    $H_1$      \\ \hline 
                & $H_0$            &                & ошибка 1 рода \\ 
                & $H_1$            &  ошибка 2 рода &               \\  
\end{tabular}

Пример  $X_1, \dots X_n$
$H_0: X_i ~ U[0, 1]$
Допустим, сделали свой random
И первое что хотим проверить, это то что иксы имеют соответствующее распределение.

Считают, что ошибка 1 рода хуже. Берем маленькое число $\9$, строим критерий, чтобы $P$(ошибка 1 рода)$ <= \9$

$GWAS$ (genome-wide association studies) — полный геномный поиск ассоциаций.
Задача такая: генотип, фенотип тыры-пыры.  Хочется по генотипу предсказывать фенотип . Пример: есть всякие нехорошие заболевания. Они опасные, но профилактика вроде есть(профилактика дешевле лечения). Очень хочется иметь геном и посмотреть на предрасположенность. Исходя из этого делать нужную профилактику.  Хочется в ДНК найти места, которые говорят о предрасположенности.  Задача: берем место в ДНК — первый признак, и заболевание(есть или нет) и проверяем зависимы они или независимы.

Попробуем смотреть на выборку и понимать, есть ли надежда решать какие-нибудь такие задачи.

## Выборные характеристики как оценки генеральных
Неестественный пример, но объяснит почему реально решать задачи описанные выше.

\10 = \mathbb{1}

Пусть есть наблюдения $X_1, \dots X_n ~ F$
Рассмотрим следующий объект:
$F_n(t) = @1/n@ \cdot \#\{i: X_i < t\} = @1/n@ \sum \limits_{i = 1}^{n} \10_{(X_i, \infty)}(t)$ (1)
                            (то есть это хорошая оценка эмпирической ф.р)
$F_n$ — эмпирическая ф.р., $\#$ — мощность множества

Посчитаем кое-что:
$E[F_n(t)] = E[\10_{(X_1, \infty)}(t)] = P(X_1 < t) = F(t)$
получили, что это несмещенная оценка эмпирической ф.р.
                        
Вспомним ЗБЧ$ => F_n(t) \over{$P$} -> F(t)$

$D[F_n(t)] = D(@1/n@ * \sum \10 \{...\}) = @1/n^2@ D(\sum\10\{\dots\}) = @1/n^2@ *\sum D[\10\{\dots\}] = @1/n@ *D(\10_{X_1, \infty}(t)) = @1/n@ *F(t) *(1 - F(t))$

Асимптотическая нормальность оценок. Оценка имеет нормальное распределение, то она так называется.
                                          
Из ЦПТ имеем:
$\sqrt{n} \cdot @ F_n(t) - F(t) /  \sqrt{F(t) \cdot (1-F(t))}@ \over{$d$} —> N(0, 1)$

Т. Гливенко-Кантелли. $P (\under{$t$} \sup| F_n(t) - F(t)|) \under{$n -> \infty$} -> 0) = 1$
Без д-ва.

Эмпирическая ф.р. сходится к истинной ф.р. то есть по выборке можно приблизить истинную ф.р.(чем больше выборка тем точнее)
Возникает вопрос: если есть такой результат, то зачем мы вообще тут сидим? А проблема в том, что скорость сходимости очень медленная. Поэтому приходится придумывать свои способы для решения стат. задач.

Посмотрим на выборку
$X_1 … X_n$ -- случайные величины
$@1/n@ … @1/n@$ -- вероятности

Рассмотрим эту с.в.(забили, что $X_i$ тоже с.в.) как устроена её ф.р? она написана — (1)

## Оценка на момент

$m_k = EX^k?$
Для $k$-ого момента возьмем предыдущее распределение
$a_k = @1/n@ \sum \limits_{i = 1}^{n} X_i^k$ — выборочный момент порядка $k$, $X_i^k$ -- также это момент $F_n$ 

$Ea_k = m_k$
По ЗБЧ имеем состоятельность: $a_k \over{$P$} -> m_k$
$EX^{2k} < \infty =>$ асимптотическая нормальность тоже есть

## Квантили

\11 = \zeta

Квантили порядка $p$ это $\11_p : F(\11_p) = p$ -- решение такого уравнения

TODO : image

Научимся оценивать такие квантили: 
$Z_p = X_{([np] + 1)}$

Опр. $X_1, \dots X_n$
$X_{(1)} <= \dots <= X_{(n)}$ — вариационный ряд
Если ф.р. непрерывна, то все неравенства строгие
$X_{(k)}$ - $k$-я порядковая статистика

Теорема. $p \in (0, 1), \exists F' = f$ — плотность, $f(\11_p) != 0$
$=> \sqrt{n} (Z_p - \11_p)) \over{$d$} -> N(0, @p(1-p)/f^2(\11_p)@)$

Д-во: Зафиксируем $t$. $P( \sqrt{n}\cdot(Z_p - \11_p < t) = P(Z_p < \11_p + @t/\sqrt{n}@) = (2) = P(\sum \10{X_i < \11_p + @t/\sqrt{n}@} >= [np] + 1$
Здесь работает ЦПТ. Нужно подсчитать нужные сущности и засунуть в ЦПТ.

$P(X_{(k)} < t) = P(\sum\10 * {X_i < t} >= k)$ (2) ?
между $X_{(1)}$ и $t$ хотя бы $k$ наблюдений
$E[\10{X_i < \11 + @t/\sqrt{n}@}] = F(\11_p + @t/\sqrt{n}@) \over{Формула Тейлора}= F(\11_p) + F’(\11_p) \cdot @t/\sqrt{n}@ + o(@1/\sqrt{n}@) = 
p + f(\11_p)\cdot @t/\sqrt{n}@  + o(@1/\sqrt{n}@)$

$D[\10 * {X_i < \11_p + @t/\sqrt{n}}@] = F(\11_p + @t/\sqrt{n}@)(1 - F(\11_p + @t/\sqrt{n}@)) = p(1 - p)(1 + o(1))$

$P(\sum \10 * {X_i < \11_p + @t/\sqrt{n}@} >= [np] + 1) = P( @\sum ... - np - f(\11_p) + \sqrt{n} + o(\sqrt{n}) /\sqrt{np(1 - p)(1 + o(1))}@) >= @[np] + 1 - np - f(\11_p) + \sqrt{n} + o(\sqrt{n}) / \sqrt{np(1-p)(1 + o(1))}@ =$
По ЦПТ имеем:
$-> 1 - \Phi(- @f(\11_p) + o(1)/\sqrt{p(1 - p)(1 + o(1))})@ + o(1) -> 1 - \Phi(- @f(\11_p)/\sqrt{p(1-p)}@\cdot t) = \Phi(@f(\11_p)/\sqrt{p(1-p)}\cdot t@)$
где $\Phi$ -- функция распределения(непр) $=>$ можно в предположении забить на o()

Получили, что $P(\sqrt{n}\cdot(Z_p - \11_p) < t) -> \Phi(@f(\11_p)/\sqrt{p(1-p)}@\cdot t)$

Если $N ~ N(0, 1)$
$c \cdot N ~ N(0, c^2)$ $c > 0$
$P(cN < t) = P(N < @t/c@) => \Phi(@t/c@)$

Утв. Если с.в. $X ~ F$ - непр. $=> F(X) ~ U[0, 1]$
Д-во. $t \in (0, 1)$
$P(F(X) < t) = P(X < F^{-1}(t) = F(F^{-1}(t)) = t$

## Практика.
Задачи будут двух типов: подсчитать, доказать либо 
аналитически к решению не подобраться, тогда нужно будет придумать оценку и вопрос: работает или не работает(можно заставить машину считать). Прогать можно на Python или R.

Чтобы понимать, что происходит желательно повторить из теорвера примерно от начала до ЦПТ.
Прозвучало, что 26 сентября от Храброва стартует курс по теорверу, поэтому есть возможность что-то повторять.