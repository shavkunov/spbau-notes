# Лекция 2

вот вам немного "вспомогательной информации"

$X, X_1, ... -$ нез. $N(0, 1)$
Распределение $X_1^2 + ... + X_n^2$ -- распределение $X^2$ с $n$ степенями свободы
\11 = @1/n@
Распределение $@X/\sqrt{\11 * (X_1^2 + ... + X_n^2)}@$ -- распределение Стьюдента(понимаете да? да?) с $n$ ст.свободы

\1 = \overline{X}
\2 = \sigma
\5 = \chi

%\Лемма Фишера
Лемма Фишера\{
    $X_1, ... X_n ~ N(0,1)$ $iid$
    $\1 = @X_1 + ... + X_n/n@$, $S^2 = @1/n@ * \sum from i = 1 to n (X_i - \1)^2 = @1/n@ * X_i^2 - \1^2$ то
    1) $\sqrt{n} * @\1 - \theta/\2@$
    2)  $\1, S^2$ -- нез.
    3) $@n * S^2/{\2^2}@ ~ \5_{n - 1}^2$
    4) $\sqrt{n - 1} * @\1 - \theta/S@ ~ T_{n-1}$ -- распределение Стьюдента
\}

%\Утв{???}
Утв{???}
Д-во: $Z_1, ... Z_n$ - нез $N(0, \2^2)$
$C$ -- ортогональная матрица
$C(Z_1, ... Z_n(столбец)) \over{$d$} = (Z_1, ... Z_n(столбец)) = Z$
Рассмотрим х.ф.: $E[e^{i(t, z)}]$ 
Как выглядит ф.р. этого вектора: $E[e^{i(t, Cz)}] = E[e^{i(C^Tt, z)}]$, равенство по свойству матрицы(TODO : комментарий)
$E[e^{i(t, z)]} = E[e^{i *(t_1 *z_1 + ... + t_n *z_n)}] = E[e^{i *(t_1 *z_1)}] *E[e^{i *(t_n *z_n)}] = $
е от сумма -- произведение e, мат ожидание независимых - произведение мат. ожиданий
$= e^{-@\2^2 *t_1^2/2@} * e^{-@\2^2 *t_n^2/2@} = e^{-@\2^2 *||t||^2/2@}$ 
$E[e^{i(t, Cz)}] = e^{-@\2^2/2@ * ||C^T * t||^2} = e^{-@\2^2/2@ * ||t||^2}$
Ортогональная матрица не меняет длину вектора
получили такую же х.ф. что и для Z, значит, распределение совпадает
Конец д-ва

\3 = X_1 + ... + X_n

Д-во леммы Фишера: $\1 ~ N(...)$
Очевидно, что получится $E[\1] = \theta$
$D[\1] = @1/n^2@ * D[\3] = @\2^2 * n/n^2@ = @\2^2/n@$

% TODO?

Д-ли первый пункт
Рассмотрим матрицу С, первая строчка будет состоять из $@1/\sqrt{n}@$, а в остальных все что угодно, главное, чтобы она была ортогональной.

\4 = @1/\sqrt{n}@
\6 = X_1^2 + ... + X_n^2

$C((X_1, ... X_n)(столбец)) \over{$d$} =  (X_1, ... X_n)(столбец)$
$C((Y_1, ... Y_n)(столбец)) =  (Y_1, ... Y_n)(столбец)$
$Y_1 = \4 * \3$ $@Y_1/\sqrt{n}@ = \1$
$S^2 = @1/n@\sum X_i^2 - @\1^2/n@ = @1/n@\sum Y_i^2 - @Y_i^2/n@ = @1/n@ * \sum from i = 2 to n Y_i^2$

Распределение вектора Y такое же что и у вектора X.
Будем считать, что $\Theta = 0$, т.е. иначе $X_i -> X_i - \theta N(0, \2^2)$ 
$Y_i$ - нез $N(0, \2^2)$
$@Y_i/\2@$ - нез $N(0, 1)$ 
$@n * S^2/\2^2@ = \sum from i = 2 to n (@Y_i/\2@)^2 ~ \5_{n-1}^2$
получили, что на месте суммы стоит с.в. со $n - 1$ степенью свободы

Получили 2 и 3 пункты
Последний пункт: 
\12 = @\1 - \theta/S@
\13 = @1/n - 1@
\14 = @n * S^2/\2^2@
$@\sqrt{n} * \12/\13 * \14@ = @\1 - \theta/S@ * \sqrt{n - 1}$

\15 = @1/(n - 1)@
$T_{n - 1} = @X/\sqrt{\15 * (X_1^2 + ... + X_{n - 1}^2)}@$

Конец д-ва

Пачка полезных утверждений, которые будем потом как-нибудь использовать.
## Требования, предьявленные к оценкам
$X_1, X_n ~ P_{\theta}$
Есть у нас оценка: $T = T(X_1, ... X_n)$

1) несмещенность
$\theta$ $E_{\theta} T = \theta$
2) Состоятельность
$\theta$ $T_n \over{$P_{\theta}$} -> \theta$
$h$ -- непр. $ => h(T_n) \over{ $P_{\theta}$} -> h(\theta)$

\7 = P_{\theta}
\8 = \theta

$\eps > 0$ $\7(|h(T_n) - h(\theta)| > \eps) <= \7(|T_n - \8| > \delta)$, $\delta$ -- из определения непрырывности.
Определение непрерывности: $\forall \eps \exists \delta > 0:$ $|t - \theta| < \delta$ $=> |h(t) - h(\8)| < \eps$

3) Ассимптотическая нормальность 
$\sqrt{n} * (T_n - \theta) \over{$d$} -> N(0, \2^2(\theta))$
Корень из n, потому что многие теоремы устроены как "средние"
$\exists h' != 0$
$=> \sqrt{n} * (h(T_n) - h(\theta)) \over{$d$} -> N(0, @h'(\theta)^2 / \2^2(\8) @)$
$h(T_n) = h(\8) + h'(\8)(T_n - \8) + o(...)$
$\sqrt{n} *(h(T_n) - h(\8)) = \sqrt{n} * h'(\8) *(T_n - \8) + o(...)$
$h'(\8) *(T_n - \8) -> h'(\8) * N(0, \2^2(\theta)) = N(0, @h'(\theta)^2 / \2^2(\8) @)$

Раньше мы что-то говорили про оценку. Но а как вообще ее получить? Даже если плохую.
## Метод моментов

$X_1, ... X_n ~ \7$, $\theta \in \Theta \subset \R^d$
$E_{\8}[g(X_1)]$ $@1/n@ * \sum from i = 1 to n g(X_i)$, где $g: \R -> \R^d$ -- некоторая функция
Заранее непонятно, какая функция g хорошая
Приравняем: $E_{\8}[g(X_1)] = @1/n@ * \sum from i = 1 to n g(X_i)$

Решение этого уравнения($\overline{\8} \in \Theta$) и есть оценка метода моментов.

Пример: 
обычно: g(x) = $(x, x^2,... x^d)$(столбец)
И получается система матожиданий...

TODO : знак системы
Хотим, чтобы первые d моментов(а я хочу спать) приблизительно совпали
$E_{\overline{\8}}[X] = \1$
$E_{\overline{\8}}[X^2] = @1/n@ * (X_1^2 + ... + X_n^2)$
$\vdots$
$E_{\overline{\8}}[X^d] = @1/n@ * (X_1^d + ... + X_n^d)$
TODO : что она вообще значит

Скажите кто-нибудь, что здесь происходит, пожалуйста
Скорее всего, это пример
$\8 \in \Theta \subset \R$
$g: \R -> \R$
$E_{\8}[g(X_1)] = h(\8)$
$h(\8) = @1/n@ * \sum from i=1 to n g(X_i)$
Пусть h - непр и $\exists h^{-1}$
$\overline{\8} = h^{-1}(@1/n@ * \sum from i=1 to n g(X_i))$

\9 = @1/n@ *\sum from i=1 to n g(X_i)

1) Несмещенность $E[\9] = h(\8)$
$E[h^{-1}(\9) = \8 = h^{-1}(h(\8)) = h^{-1}(E[\9])]$
обычно, это неверно(wuuut) и тут есть какая-то связь с неравенством Йенсена 
2) состоятельность
h непр. $\exists h^{-1} => h^{-1} непр$
ЗБЧ: $\9 \over{$\7$} -> E[g(X_1)] = h(\8)$
$=> h^{-1}(\9) \over{$\7$} -> h^{-1}(h(\8)) = \8$
3) асимптотическая нормальность $E[g(X)^2] < \infty$
$\sqrt{n} * (\9 - h(\8)) \over{$d$} -> N(0, \2^2(\8))$
ЦПТ: $\exists h' != 0 => \exists {h'}^{-1} != 0 => \overline{\8}$ -- асимптотическая нормальность