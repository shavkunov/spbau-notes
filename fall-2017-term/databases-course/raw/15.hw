# Лекция 15

Разминка.
$R_2(X)R_1(Z)W_2(Z)R_3(X)W_3(Y)W_2(X)W_1(Y)$
$T_3 T_1 T_2$
???

## Что может пойти не так

1) Ошибки оператора/человека/программы, неверное данные

решение: ограничения/проверка/святая вода/бубен

2) Сбой носителя

решение: синхронная запись на несколько дисков

RAID с зефирками -- массив сильных и независимых дисков

3) Системый сбой
отключение электричества, ошибка в коде СУБД

4) Катастрофически сбой

зональный -- сбой в датацентре

региональный/континентальный -- локаут в энергосистеме, ядерный взрыв/цунами/прочее

## Основные проблема
1) записи, сделанные подтвердившиеся транзакциями не долетели до диска
2) запись долетела до диска, транзакция не подтвердилась

Поговорим про первый случай.
Тут нам поможет буфер менеджер. (КАРТИНКА). Транзакции как-то общаются с буфером, буфер в какой-то момент записывает все данные на диск. Запись на диск может произойти значительное позже. Поэтому в момент после транзакции и до записи на диск отключится электричество, то все будет плохо.
В реальности происходит все немного посложнее, но в основе лежат некоторые простые концепции.
Как нам восстановить систему после такого сбоя? Нам бы хотелось, чтобы транзакция была бы выполнена. Первое что приходит в голову -- просто запомнить транзакцию. Но нам сложно гарантировать детерминнированность, в том смысле, что повторный ввод транзакции даст те же результаты. 

## Журнал(log)

- файл append-only(добавляем только в конец файла данные -- с точки зрения ФС)
- место, где тоже появляются изменения
- изменения в журнале записываются до того, как они появляются в таблицах

по сути, СУБД записывает данные дважды
Прежде чем записать Х на диск, Х появляется в конце журнала в виде некоторой записи.
Таким образом, порядок записи Х такой: запись в транзакции, записывает изменения в журнал, потом запись в табличное пространство. Это называется write-ahed logging -- опережающее журналирование.

Не является ли это каким-то вредительством?(снижение производительности в 2 раза)
Эти два места независимы, поэтому можно распараллелить. Операции с файлами, открытые на только запись, более эффективны, в то время как табличное пространство -- разрозненное. Поэтому, суммарно это все тормозится все на $ ~10$\%.

Теперь конкретные стратегии, как все записывается в журнал
## Undo logging

Записи в журнале.
<START $T_i$>
<START $T_j$>
<$T_i$, X, OLD(X)> OLD(X) -- полностью Х или дифф. главное, чтобы мы смоги восстановить
<COMMIT $T_i$>
<ABORT $T_j$>

### Стратегия undo
- запись в журнале предшествует записи в табличном пространстве.
Т.е. $t_1$: <$T_i$, X, OLD(X)>, $t_2$: <OUTPUT(X)>, и $t_1 < t_2$ -- время
- <COMMIT $T_i$> появлется после записи всех измененных $T_i$ объектов на диск.

Пример. A = 50, B = 100. Транзакция будет такой: 
A \*= 2
B \*= 2
\begin{tabular}{c c}
Что происходить в реальности & Undo log журнал
 & <START T>
READ(A)  &
A \*= 2   &
WRITE(A) -- запись в буфере & <T, A, 50>
READ(B) & 
B \*= 2  &
WRITE(B) & <T, B, 100>
Flush log? & 
OUTPUT(A) &
OUTPUT(B) &
& <COMMIT T>
\end{tabular}

## Восстановление с Undo журналом

1) Найти все подтвердившиеся транзакции(есть слово commit)
2) сканируя журнал с конца: отменять неподтвердившихся транзакции

Журнал может стать довольно большим. Это и место на диске, и процесс восстановления с большим журналом занимается больше времени.

### Checkpointing
контрольные точки

Наивная идея

1) подождать пока не будет активных транзакций
2) сделать sync
3) весь журнал можно выкинуть

Если транзакции немного, то это вполне себе работающая стратегия

<START CHECKPOINT($T_1$, ... $T_n$)>
<START $T_{n + 1}$>
<COMMIT $T_1$>
<END CHECKPOINT> -- когда завершатся транзакциии $T_1,... T_n$.

Если видим с конца и видим окончание чекпоинта? Мы понимаем, что $T_1,... T_n$ закрылись, поэтому нас интересуют другие.
## Восстановление с checkpoint
при чтении журнала с конца 
1) первым нашли <END CHECKPOINT>, значит все интересующие нас транзакции, которые мы бы хотели откатить -- начались после <START CHECKPOINT>, поэтому достаточно прочитать до старта чекпоинта.
2) если мы встретили <START CHECKPOINT($T_1, ... T_n$)>, т.е. сбой произошел во время контрольной точки, поэтому читать стоит до начала самой ранней транзакции из <START CHECKPOINT> т.е. из $T_1, ... T_n$.

## Redo logging

1) В журнал пишет новое значение изменного элемента
2) write-ahead logging сохраняется
3) никаких OUTPUT пока не появится COMMIT

Рассмотрим на том же примере

A = 50, B = 100. Транзакция будет такой: 
A \*= 2
B \*= 2
\begin{tabular}{c c}
Что происходить в реальности & Redo log журнал
 & <START T>
READ(A)  &
A \*= 2   &
WRITE(A) -- запись в буфере & <T, A, 100>
READ(B) & 
B \*= 2  &
WRITE(B) & <T, B, 200>
& <COMMIT T>
Flush log? & 
OUTPUT(A) &
OUTPUT(B) &
\end{tabular}

Это нам гарантирует следующее: если транзакция не подтвердилась, то изменения не запишутся на диск.
С подтвержденными чуть посложнее. Их изменения до диска долетят не сразу. 

## Восстановление с Redo журналом

1) Найти все подтвердившиеся транзакции(есть слово commit)
2) сканируя журнал с НАЧАЛА: применять подтвердившиеся транзакции, т.е. записывать новое значение элемента

записываем грязные страницы измененные подтвердившимся транзакциями

При восстановлении

1) если есть <END CHECKPOINT> то нас интересует только транзакции из <START CHECKPOINT> и самая ранная из них
2) если назавереный checkpoint то нельзя дойти до самой ранней, потому что мы не знаем какие изменения долетели из предыдущих транзакции. Но, если мы дойдем до предыдущего checkpoint -- то нужные гарантии мы получим. Т.е. нужно идти до начала самой ранней транзакции из предыдущего checkpoint. 

## Undo-Redo Logging

1) <T, X, Old(X), new(X)>
2) write-ahead logging

## Применение журнала
Помимо восстановления после сбоя, журнал можно использовать и другим образом.
Если передавать журнал куда-то, то можно получить практически копию БД в реалтайме(репликация)
Еще один плюс Redo: можно получить копию БД на какой-то любой момент времени. Т.е. можно делать копию БД раз в неделю и потом хранить только записи журналов.(непрерывный инкрементальный backup)

Существуют Log based database, который хранят все записи в журнале.